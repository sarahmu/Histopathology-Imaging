{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import os\n",
    "from data_loader import Dataset\n",
    "from utils import local_clock, preprocess, postprocess, show_images, save_image\n",
    "from evaluate import evaluate_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "def generator(x, is_training, output_channels=4, filters = [128,128,128,256,512,512,512,512], kernel_size = 4, stride = 2):\n",
    "    with tf.variable_scope('generator'):\n",
    "        layers = []\n",
    "        # Encoder:\n",
    "        x = tf.layers.conv2d(inputs = x,\n",
    "                             filters = filters[0],\n",
    "                             kernel_size = 1,\n",
    "                             strides = 1,\n",
    "                             padding = 'same',\n",
    "                             kernel_initializer = tf.contrib.layers.xavier_initializer()) \n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x =  tf.nn.leaky_relu(x)\n",
    "        layers.append(x)\n",
    "        for i in range(1, len(filters)):\n",
    "            x = tf.layers.conv2d(inputs = x,\n",
    "                                 filters = filters[i],\n",
    "                                 kernel_size = kernel_size,\n",
    "                                 strides = stride,\n",
    "                                 padding = 'same',\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer())  \n",
    "            x = tf.layers.batch_normalization(x, training=is_training)\n",
    "            x =  tf.nn.leaky_relu(x)\n",
    "        # save contracting path layers to be used for skip connections\n",
    "            layers.append(x)\n",
    "            \n",
    "        \n",
    "        # Decoder:\n",
    "        for i in reversed(range(len(filters)-1)):\n",
    "            x = tf.layers.conv2d_transpose(inputs = x,\n",
    "                                           filters = filters[i],\n",
    "                                           kernel_size = kernel_size,\n",
    "                                           strides = stride,\n",
    "                                           padding = 'same',\n",
    "                                           kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "            x = tf.layers.batch_normalization(x, training=is_training)\n",
    "            x =  tf.nn.relu(x)\n",
    "        # concat the layer from the contracting path with the output of the current layer\n",
    "        # concat only the channels (axis=3)\n",
    "            x = tf.concat([layers[i], x], axis=3)\n",
    "            # layers.append(x)\n",
    "        x = tf.layers.conv2d(inputs = x,\n",
    "                             filters = output_channels,\n",
    "                             kernel_size = 1,\n",
    "                             strides = 1,\n",
    "                             padding = 'same',\n",
    "                             activation = tf.nn.tanh,\n",
    "                             kernel_initializer = tf.contrib.layers.xavier_initializer())   \n",
    "        # layers.append(x)\n",
    "        # return layers\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "def discriminator(x, is_training, filters = [64,128,256,512] , kernel_size = 4, stride = 2): # conditional GAN\n",
    "    \"\"\"\n",
    "    filters: Integer, the dimensionality of the output space (i.e. the number of filters in the convolution).\n",
    "    kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. \n",
    "                 Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    strides: An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. \n",
    "             Can be a single integer to specify the same value for all spatial dimensions. \n",
    "             Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n",
    "    \n",
    "    filters: a series of 4x4 convolutional layers with stride 2 with the number of channels being doubled after each downsampling.\n",
    "    All convolution layers are followed by batch normalization, leaky ReLU activation. \n",
    "    After the last layer, a convolution is applied to map to a 1 dimensional output, \n",
    "        followed by a sigmoid function to return a probability value of the input being real or fake\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"discriminator\"): \n",
    "        # layers = []\n",
    "        for i in range(len(filters)):\n",
    "            x = tf.layers.conv2d(inputs = x,\n",
    "                                 filters = filters[i],\n",
    "                                 kernel_size = kernel_size,\n",
    "                                 strides = stride,\n",
    "                                 padding = 'same',\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer())           \n",
    "            if i != 0: # Do not use batch-norm in the first layer\n",
    "                x = tf.layers.batch_normalization(x, training=is_training)\n",
    "            x =  tf.nn.leaky_relu(x)\n",
    "            # layers.append(x)\n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "        logit = tf.layers.dense(inputs = x, units=1, kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "        # layers.append(logit)\n",
    "        # return layers\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_loss(logits_real, logits_fake):\n",
    "    \"\"\"Compute the GAN loss.\n",
    "    \n",
    "    Inputs:\n",
    "    - logits_real: Tensor, shape [batch_size, 1], output of discriminator\n",
    "        Unnormalized score that the image is real for each real image\n",
    "    - logits_fake: Tensor, shape[batch_size, 1], output of discriminator\n",
    "        Unnormalized score that the image is real for each fake image\n",
    "    \n",
    "    Returns:\n",
    "    - D_loss: discriminator loss scalar\n",
    "    - G_loss: generator loss scalar\n",
    "    \n",
    "    Note: For the discriminator loss, do the averaging separately for\n",
    "    its two components, and then add them together (instead of averaging once at the very end).\n",
    "    \"\"\"\n",
    "    G_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(logits_fake), logits=logits_fake)\n",
    "    G_loss = tf.reduce_mean(G_loss)\n",
    "    \n",
    "    D_real_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(logits_real), logits=logits_real)\n",
    "    D_real_loss = tf.reduce_mean(D_real_loss)\n",
    "    D_fake_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(logits_fake), logits=logits_fake)\n",
    "    D_fake_loss = tf.reduce_mean(D_fake_loss)\n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "    return D_loss, G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_loss(fake_imgs, real_imgs, reg=127.5):\n",
    "    \"\"\"\n",
    "    Compute the L1 loss between fake images and real images.\n",
    "    \n",
    "    Inputs:\n",
    "    - fake_imgs: Tensor with shape [batch_size, H, W, C], output of generator\n",
    "    - real_imgs: Tensor with shape [batch_size, H, W, C], fed into the graph\n",
    "    - reg: Float for the regularization constant. Default to 127.5 for RGBA scheme (0-255).\n",
    "    \n",
    "    Outputs:\n",
    "    - loss: L1 loss scalar\n",
    "    \"\"\"\n",
    "    fake_flat = tf.contrib.layers.flatten(fake_imgs)\n",
    "    real_flat = tf.contrib.layers.flatten(real_imgs)\n",
    "    loss = tf.reduce_mean(tf.abs(fake_flat - real_flat))\n",
    "    return reg * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solvers(D_lr=2e-4, G_lr=2e-4, beta1=0.5):\n",
    "    \"\"\"Create solvers for GAN training.\n",
    "    \n",
    "    Inputs:\n",
    "    - D_lr: learning rate for the discriminator\n",
    "    - G_lr: learning rate for the generator\n",
    "    - beta1: beta1 parameter for both solvers (first moment decay)\n",
    "    \n",
    "    Returns:\n",
    "    - D_solver: instance of tf.train.AdamOptimizer with correct learning_rate and beta1\n",
    "    - G_solver: instance of tf.train.AdamOptimizer with correct learning_rate and beta1\n",
    "    \"\"\"\n",
    "    D_solver = tf.train.AdamOptimizer(D_lr, beta1)\n",
    "    G_solver = tf.train.AdamOptimizer(G_lr, beta1)\n",
    "    return D_solver, G_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# Construct computational graph\n",
    "device = '/gpu:0'\n",
    "tf.reset_default_graph() # reset the graph\n",
    "with tf.device(device):\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    gray_img = tf.placeholder(tf.float32, [None, 256, 256, 1])\n",
    "    color_img = tf.placeholder(tf.float32, [None, 256, 256, 4])\n",
    "    \n",
    "    pair_real = tf.concat([gray_img, color_img], axis=3)\n",
    "    G_sample = generator(gray_img, is_training)\n",
    "    pair_fake = tf.concat([gray_img, G_sample], axis=3)\n",
    "\n",
    "    with tf.variable_scope('') as scope:\n",
    "        logits_real = discriminator(pair_real, is_training)\n",
    "        scope.reuse_variables()\n",
    "        logits_fake = discriminator(pair_fake, is_training)\n",
    "    \n",
    "    # Get the list of trainable variables for the discriminator and generator\n",
    "    D_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'discriminator')\n",
    "    G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator')\n",
    "    \n",
    "    # Get solvers\n",
    "    D_solver, G_solver = get_solvers()\n",
    "    \n",
    "    # Compute the losses\n",
    "    D_loss, G_loss = gan_loss(logits_real, logits_fake)\n",
    "    img_loss = l1_loss(G_sample, color_img)\n",
    "    \n",
    "    # Set up the training operations\n",
    "    D_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'discriminator')\n",
    "    with tf.control_dependencies(D_update_ops):\n",
    "        D_train_op = D_solver.minimize(D_loss, var_list=D_vars)\n",
    "    \n",
    "    G_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'generator')\n",
    "    with tf.control_dependencies(G_update_ops):\n",
    "        G_train_op = G_solver.minimize(G_loss + img_loss, var_list=G_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data set\n",
    "train_data = Dataset('data/gray_examples_256/', 'data/color_examples_256/', 16, 256, shuffle=True)\n",
    "train_example_data = Dataset('data/gray_examples_256/', 'data/color_examples_256/', 16, 256, shuffle=False)\n",
    "val_data = Dataset('data/gray_examples_256/', 'data/color_examples_256/', 16, 256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 2e-4\n",
    "beta1 = 0.5\n",
    "reg = 127.5\n",
    "\n",
    "# Master output directories\n",
    "output_dir = '/home/shared/chris/Histopathology-Imaging/gan_l1_0528/'\n",
    "val_dir = output_dir + 'val_results/'\n",
    "val_img_dir = val_dir + 'imgs/'\n",
    "train_dir = output_dir + 'train_results/'\n",
    "trained_sess_dir = output_dir + 'trained_sess/'\n",
    "if not os.path.exists(val_dir):\n",
    "    os.makedirs(val_dir)\n",
    "if not os.path.exists(val_img_dir):\n",
    "    os.makedirs(val_img_dir)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(trained_sess_dir):\n",
    "    os.makedirs(trained_sess_dir)\n",
    "\n",
    "# Output file paths\n",
    "train_log_file = train_dir + 'train_log_lr={}_beta1={}_reg={}.txt'.format(lr, beta1, reg)\n",
    "train_img_file = train_dir + 'train_gen_examples_epoch_'\n",
    "val_log_file = val_dir + 'val_log_lr={}_beta1={}_reg={}.txt'.format(lr, beta1, reg)\n",
    "val_csv_file = val_dir + 'val_metrics_lr={}_beta1={}_reg={}'.format(lr, beta1, reg)\n",
    "\n",
    "# Initialize the log files\n",
    "start_msg = local_clock() + '  Started training model with learning rate={}, beta1={}, reg={}\\n'.format(lr, beta1, reg)\n",
    "with open(train_log_file, 'w') as handle:\n",
    "    handle.write(start_msg)\n",
    "with open(val_log_file, 'w') as handle:\n",
    "    handle.write(start_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 28 22:07:44 2018  Started epoch 0\n",
      "Mon May 28 22:07:51 2018  Epoch 0  D loss: 0.1589  G loss: 4.6346  img loss: 74.4301\n",
      "Mon May 28 22:08:07 2018  Finished epoch 0\n",
      "\n",
      "Mon May 28 22:08:07 2018  Started epoch 1\n",
      "Mon May 28 22:08:10 2018  Epoch 1  D loss: 0.0974  G loss: 9.2042  img loss: 62.1175\n",
      "Mon May 28 22:08:25 2018  Finished epoch 1\n",
      "\n",
      "Mon May 28 22:08:25 2018  Started epoch 2\n",
      "Mon May 28 22:08:28 2018  Epoch 2  D loss: 0.5330  G loss: 17.8175  img loss: 51.6276\n",
      "Mon May 28 22:08:44 2018  Finished epoch 2\n",
      "\n",
      "Mon May 28 22:08:44 2018  Started epoch 3\n",
      "Mon May 28 22:08:46 2018  Epoch 3  D loss: 0.0134  G loss: 7.3397  img loss: 48.1348\n",
      "Mon May 28 22:09:02 2018  Finished epoch 3\n",
      "\n",
      "Mon May 28 22:09:02 2018  Started epoch 4\n",
      "Mon May 28 22:09:05 2018  Epoch 4  D loss: 0.0735  G loss: 7.2856  img loss: 46.2591\n",
      "Mon May 28 22:09:21 2018  Finished epoch 4\n",
      "\n",
      "Mon May 28 22:09:21 2018  Started epoch 5\n",
      "Mon May 28 22:09:24 2018  Epoch 5  D loss: 1.5592  G loss: 20.0963  img loss: 39.0119\n",
      "Mon May 28 22:09:39 2018  Finished epoch 5\n",
      "\n",
      "Mon May 28 22:09:39 2018  Started epoch 6\n",
      "Mon May 28 22:09:42 2018  Epoch 6  D loss: 0.0000  G loss: 23.1070  img loss: 34.3968\n",
      "Mon May 28 22:09:58 2018  Finished epoch 6\n",
      "\n",
      "Mon May 28 22:09:58 2018  Started epoch 7\n",
      "Mon May 28 22:10:01 2018  Epoch 7  D loss: 0.4900  G loss: 23.0661  img loss: 35.0148\n",
      "Mon May 28 22:10:16 2018  Finished epoch 7\n",
      "\n",
      "Mon May 28 22:10:16 2018  Started epoch 8\n",
      "Mon May 28 22:10:19 2018  Epoch 8  D loss: 0.0000  G loss: 24.8081  img loss: 31.2882\n",
      "Mon May 28 22:10:35 2018  Finished epoch 8\n",
      "\n",
      "Mon May 28 22:10:35 2018  Started epoch 9\n",
      "Mon May 28 22:10:38 2018  Epoch 9  D loss: 0.0000  G loss: 19.2957  img loss: 31.7630\n",
      "Mon May 28 22:10:53 2018  Finished epoch 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(num_epochs):\n",
    "        print(local_clock() + '  Started epoch %d' % (epoch))\n",
    "        for t, (gray_img_np, color_img_np) in enumerate(train_data):\n",
    "            gray_processed_np = preprocess(gray_img_np)\n",
    "            color_processed_np = preprocess(color_img_np)\n",
    "            feed_dict = {gray_img: gray_processed_np, color_img: color_processed_np, is_training: True}\n",
    "            _, D_loss_np = sess.run([D_train_op, D_loss], feed_dict=feed_dict)\n",
    "            _, G_loss_np, img_loss_np = sess.run([G_train_op, G_loss, img_loss], feed_dict=feed_dict)\n",
    "\n",
    "        # Save the results to the train log file\n",
    "        epoch_train_time = local_clock() + '\\n'\n",
    "        epoch_train_msg = 'Epoch %d  D loss: %0.4f  G loss: %0.4f  img loss: %0.4f' % (epoch, D_loss_np, G_loss_np, img_loss_np)\n",
    "        print(local_clock() + '  ' + epoch_train_msg)\n",
    "        epoch_train_msg += '\\n'\n",
    "        with open(train_log_file, 'a') as handle:\n",
    "            handle.write('\\n')\n",
    "            handle.write(epoch_train_time)\n",
    "            handle.write(epoch_train_msg)\n",
    "        \n",
    "        # Save examples of generated images\n",
    "        for j, (gray_example_np, color_example_np) in enumerate(train_example_data):\n",
    "            gray_example_processed_np = preprocess(gray_example_np)\n",
    "            color_example_processed_np = preprocess(color_example_np)\n",
    "            break # only load the first batch as examples\n",
    "        example_feed_dict = {gray_img: gray_example_processed_np, \n",
    "                             color_img: color_example_processed_np, \n",
    "                             is_training: False}\n",
    "        gen_example_np = sess.run(G_sample, feed_dict=example_feed_dict)\n",
    "        gen_example_np = postprocess(gen_example_np)\n",
    "        show_images(gen_example_np, post_process=False, save=True, filepath=train_img_file + str(epoch) + '.png')\n",
    "        \n",
    "        # Evaluate on the validation data set\n",
    "        val_log_note = 'Epoch ' + str(epoch)\n",
    "        epoch_val_img_dir = val_img_dir + 'epoch' + str(epoch) + '/'\n",
    "        if not os.path.exists(epoch_val_img_dir):\n",
    "            os.makedirs(epoch_val_img_dir)\n",
    "        epoch_val_csv = val_csv_file + '_epoch' + str(epoch) + '.csv'\n",
    "        evaluate_model(sess=sess,\n",
    "                       graph_gray=gray_img, \n",
    "                       graph_color=color_img, \n",
    "                       graph_training=is_training,\n",
    "                       graph_D_loss=D_loss, \n",
    "                       graph_G_loss=G_loss, \n",
    "                       graph_img_loss=img_loss, \n",
    "                       graph_G_sample=G_sample, \n",
    "                       dataset=val_data, \n",
    "                       log_filename=val_log_file, \n",
    "                       log_note=val_log_note, \n",
    "                       csv_filename=epoch_val_csv, \n",
    "                       output_imgs=True, \n",
    "                       img_dir=epoch_val_img_dir)\n",
    "        \n",
    "        # Save the session when the epoch is done\n",
    "        saver = tf.train.Saver()\n",
    "        sess_name = trained_sess_dir + 'gan_epoch' + str(epoch)\n",
    "        saver.save(sess, sess_name)\n",
    "\n",
    "        print(local_clock() + '  Finished epoch %d' % (epoch))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(train_data_dir, val_data_dir, output_dir, D_lr, G_lr, beta1, reg, num_epochs, batch_size=16, eval_val=True, save_eval_img=True, device='/gpu:0', img_dim=256):\n",
    "    # Set up output directories    \n",
    "    val_dir = output_dir + 'val_results/'\n",
    "    val_img_dir = val_dir + 'imgs/'\n",
    "    train_dir = output_dir + 'train_results/'\n",
    "    trained_sess_dir = output_dir + 'trained_sess/'\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.makedirs(val_dir)\n",
    "    if not os.path.exists(val_img_dir):\n",
    "        os.makedirs(val_img_dir)\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    if not os.path.exists(trained_sess_dir):\n",
    "        os.makedirs(trained_sess_dir)\n",
    "\n",
    "    # Output file paths\n",
    "    train_log_file = train_dir + 'train_log_Dlr={}_Glr={}_beta1={}_reg={}.txt'.format(D_lr, G_lr, beta1, reg)\n",
    "    train_img_file = train_dir + 'train_gen_examples_epoch_'\n",
    "    val_log_file = val_dir + 'val_log_Dlr={}_Glr={}_beta1={}_reg={}.txt'.format(D_lr, G_lr, beta1, reg)\n",
    "    val_csv_file = val_dir + 'val_metrics_Dlr={}_Glr={}_beta1={}_reg={}'.format(D_lr, G_lr, beta1, reg)\n",
    "\n",
    "    # Initialize the log files\n",
    "    start_msg = local_clock() + '  Started training model with D_lr={}, G_lr={}, beta1={}, reg={}\\n'.format(D_lr, G_lr, beta1, reg)\n",
    "    with open(train_log_file, 'w') as handle:\n",
    "        handle.write(start_msg)\n",
    "    with open(val_log_file, 'w') as handle:\n",
    "        handle.write(start_msg)\n",
    "\n",
    "    # Get the data set\n",
    "    train_gray_dir = train_data_dir + 'gray/'\n",
    "    train_color_dir = train_data_dir + 'color/'\n",
    "    val_gray_dir = val_data_dir + 'gray/'\n",
    "    val_color_dir = val_data_dir + 'color/'\n",
    "    train_data = Dataset(train_gray_dir, train_color_dir, batch_size, img_dim, shuffle=True)\n",
    "    train_example_data = Dataset(train_gray_dir, train_color_dir, batch_size, img_dim, shuffle=False)\n",
    "    val_data = Dataset(val_gray_dir, val_color_dir, batch_size, img_dim, shuffle=False)\n",
    "    \n",
    "    # Construct computational graph\n",
    "    tf.reset_default_graph() # reset the graph\n",
    "    with tf.device(device):\n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        gray_img = tf.placeholder(tf.float32, [None, img_dim, img_dim, 1])\n",
    "        color_img = tf.placeholder(tf.float32, [None, img_dim, img_dim, 4])\n",
    "\n",
    "        pair_real = tf.concat([gray_img, color_img], axis=3)\n",
    "        G_sample = generator(gray_img, is_training)\n",
    "        pair_fake = tf.concat([gray_img, G_sample], axis=3)\n",
    "\n",
    "        with tf.variable_scope('') as scope:\n",
    "            logits_real = discriminator(pair_real, is_training)\n",
    "            scope.reuse_variables()\n",
    "            logits_fake = discriminator(pair_fake, is_training)\n",
    "\n",
    "        # Get the list of trainable variables for the discriminator and generator\n",
    "        D_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'discriminator')\n",
    "        G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator')\n",
    "\n",
    "        # Get solvers\n",
    "        D_solver, G_solver = get_solvers(D_lr=D_lr, G_lr=G_lr, beta1=beta1)\n",
    "\n",
    "        # Compute the losses\n",
    "        D_loss, G_loss = gan_loss(logits_real, logits_fake)\n",
    "        img_loss = l1_loss(G_sample, color_img, reg=reg)\n",
    "\n",
    "        # Set up the training operations\n",
    "        D_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'discriminator')\n",
    "        with tf.control_dependencies(D_update_ops):\n",
    "            D_train_op = D_solver.minimize(D_loss, var_list=D_vars)\n",
    "\n",
    "        G_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'generator')\n",
    "        with tf.control_dependencies(G_update_ops):\n",
    "            G_train_op = G_solver.minimize(G_loss + img_loss, var_list=G_vars)\n",
    "\n",
    "    # Training loop\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(num_epochs):\n",
    "            print(local_clock() + '  Started epoch %d' % (epoch))\n",
    "            for t, (gray_img_np, color_img_np) in enumerate(train_data):\n",
    "                gray_processed_np = preprocess(gray_img_np)\n",
    "                color_processed_np = preprocess(color_img_np)\n",
    "                feed_dict = {gray_img: gray_processed_np, color_img: color_processed_np, is_training: True}\n",
    "                _, D_loss_np = sess.run([D_train_op, D_loss], feed_dict=feed_dict)\n",
    "                _, G_loss_np, img_loss_np = sess.run([G_train_op, G_loss, img_loss], feed_dict=feed_dict)\n",
    "\n",
    "            # Save the results to the train log file\n",
    "            epoch_train_time = local_clock() + '\\n'\n",
    "            epoch_train_msg = 'Epoch %d  D loss: %0.4f  G loss: %0.4f  img loss: %0.4f' % (epoch, D_loss_np, G_loss_np, img_loss_np)\n",
    "            print(local_clock() + '  ' + epoch_train_msg)\n",
    "            epoch_train_msg += '\\n'\n",
    "            with open(train_log_file, 'a') as handle:\n",
    "                handle.write('\\n')\n",
    "                handle.write(epoch_train_time)\n",
    "                handle.write(epoch_train_msg)\n",
    "\n",
    "            # Save examples of generated images\n",
    "            for j, (gray_example_np, color_example_np) in enumerate(train_example_data):\n",
    "                gray_example_processed_np = preprocess(gray_example_np)\n",
    "                color_example_processed_np = preprocess(color_example_np)\n",
    "                break # only load the first batch as examples\n",
    "            example_feed_dict = {gray_img: gray_example_processed_np, \n",
    "                                 color_img: color_example_processed_np, \n",
    "                                 is_training: False}\n",
    "            gen_example_np = sess.run(G_sample, feed_dict=example_feed_dict)\n",
    "            gen_example_np = postprocess(gen_example_np)\n",
    "            show_images(gen_example_np, post_process=False, save=True, filepath=train_img_file + str(epoch) + '.png')\n",
    "\n",
    "            # If true, evaluate on the validation data set\n",
    "            if eval_val:\n",
    "                val_log_note = 'Epoch ' + str(epoch)\n",
    "                epoch_val_img_dir = val_img_dir + 'epoch' + str(epoch) + '/'\n",
    "                if not os.path.exists(epoch_val_img_dir):\n",
    "                    os.makedirs(epoch_val_img_dir)\n",
    "                epoch_val_csv = val_csv_file + '_epoch' + str(epoch) + '.csv'\n",
    "                evaluate_model(sess=sess,\n",
    "                               graph_gray=gray_img, \n",
    "                               graph_color=color_img, \n",
    "                               graph_training=is_training,\n",
    "                               graph_D_loss=D_loss, \n",
    "                               graph_G_loss=G_loss, \n",
    "                               graph_img_loss=img_loss, \n",
    "                               graph_G_sample=G_sample, \n",
    "                               dataset=val_data, \n",
    "                               log_filename=val_log_file, \n",
    "                               log_note=val_log_note, \n",
    "                               csv_filename=epoch_val_csv, \n",
    "                               output_imgs=save_eval_img, \n",
    "                               img_dir=epoch_val_img_dir)\n",
    "\n",
    "            # Save the session when the epoch is done\n",
    "            saver = tf.train.Saver()\n",
    "            sess_name = trained_sess_dir + 'gan_epoch' + str(epoch)\n",
    "            saver.save(sess, sess_name)\n",
    "\n",
    "            print(local_clock() + '  Finished epoch %d' % (epoch))\n",
    "            print('')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Tue May 29 17:07:49 2018  Started epoch 0\n",
      "Tue May 29 17:07:58 2018  Epoch 0  D loss: 0.2878  G loss: 12.4007  img loss: 281.0776\n",
      "Tue May 29 17:08:15 2018  Finished epoch 0\n",
      "\n",
      "Tue May 29 17:08:15 2018  Started epoch 1\n",
      "Tue May 29 17:08:19 2018  Epoch 1  D loss: 0.1007  G loss: 5.4090  img loss: 221.9584\n",
      "Tue May 29 17:08:36 2018  Finished epoch 1\n",
      "\n",
      "Tue May 29 17:08:36 2018  Started epoch 2\n",
      "Tue May 29 17:08:40 2018  Epoch 2  D loss: 0.1460  G loss: 3.7714  img loss: 198.5429\n",
      "Tue May 29 17:08:57 2018  Finished epoch 2\n",
      "\n",
      "Tue May 29 17:08:57 2018  Started epoch 3\n",
      "Tue May 29 17:09:01 2018  Epoch 3  D loss: 0.0007  G loss: 11.1351  img loss: 146.2451\n",
      "Tue May 29 17:09:18 2018  Finished epoch 3\n",
      "\n",
      "Tue May 29 17:09:18 2018  Started epoch 4\n",
      "Tue May 29 17:09:22 2018  Epoch 4  D loss: 0.0018  G loss: 7.1131  img loss: 132.8643\n",
      "Tue May 29 17:09:40 2018  Finished epoch 4\n",
      "\n",
      "Tue May 29 17:09:40 2018  Started epoch 5\n",
      "Tue May 29 17:09:44 2018  Epoch 5  D loss: 0.0005  G loss: 8.2639  img loss: 111.5916\n",
      "Tue May 29 17:10:01 2018  Finished epoch 5\n",
      "\n",
      "Tue May 29 17:10:01 2018  Started epoch 6\n",
      "Tue May 29 17:10:05 2018  Epoch 6  D loss: 0.0000  G loss: 11.9598  img loss: 105.2903\n",
      "Tue May 29 17:10:22 2018  Finished epoch 6\n",
      "\n",
      "Tue May 29 17:10:22 2018  Started epoch 7\n",
      "Tue May 29 17:10:26 2018  Epoch 7  D loss: 0.0000  G loss: 14.1649  img loss: 121.6221\n",
      "Tue May 29 17:10:42 2018  Finished epoch 7\n",
      "\n",
      "Tue May 29 17:10:42 2018  Started epoch 8\n",
      "Tue May 29 17:10:46 2018  Epoch 8  D loss: 0.0000  G loss: 11.7894  img loss: 109.7145\n",
      "Tue May 29 17:11:04 2018  Finished epoch 8\n",
      "\n",
      "Tue May 29 17:11:04 2018  Started epoch 9\n",
      "Tue May 29 17:11:08 2018  Epoch 9  D loss: 0.0000  G loss: 19.6538  img loss: 200.6907\n",
      "Tue May 29 17:11:24 2018  Finished epoch 9\n",
      "\n",
      "Tue May 29 17:11:24 2018  Started epoch 10\n",
      "Tue May 29 17:11:28 2018  Epoch 10  D loss: 0.0004  G loss: 8.5090  img loss: 76.1816\n",
      "Tue May 29 17:11:44 2018  Finished epoch 10\n",
      "\n",
      "Tue May 29 17:11:44 2018  Started epoch 11\n",
      "Tue May 29 17:11:49 2018  Epoch 11  D loss: 0.0007  G loss: 9.0022  img loss: 150.0874\n",
      "Tue May 29 17:12:05 2018  Finished epoch 11\n",
      "\n",
      "Tue May 29 17:12:05 2018  Started epoch 12\n",
      "Tue May 29 17:12:09 2018  Epoch 12  D loss: 0.0002  G loss: 11.1150  img loss: 81.1191\n",
      "Tue May 29 17:12:26 2018  Finished epoch 12\n",
      "\n",
      "Tue May 29 17:12:26 2018  Started epoch 13\n",
      "Tue May 29 17:12:30 2018  Epoch 13  D loss: 0.1163  G loss: 6.2039  img loss: 129.3829\n",
      "Tue May 29 17:12:46 2018  Finished epoch 13\n",
      "\n",
      "Tue May 29 17:12:46 2018  Started epoch 14\n",
      "Tue May 29 17:12:50 2018  Epoch 14  D loss: 0.8789  G loss: 13.2268  img loss: 86.0939\n",
      "Tue May 29 17:13:07 2018  Finished epoch 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "train_gan('/home/shared/chris/Histopathology-Imaging/testing/', \n",
    "          '/home/shared/chris/Histopathology-Imaging/testing/', \n",
    "          '/home/shared/chris/Histopathology-Imaging/gan_l1_0529/', \n",
    "          D_lr=2e-4, \n",
    "          G_lr=2e-4, \n",
    "          beta1=0.5, \n",
    "          reg=1000, \n",
    "          num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
